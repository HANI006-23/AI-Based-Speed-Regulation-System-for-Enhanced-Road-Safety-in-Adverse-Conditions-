import cv2
import numpy as np
import serial
import time

# Initialize serial communication with Arduino (Update COM port if needed)
ser = serial.Serial('COM6', 9600)  # Adjust for your COM port
time.sleep(2)  # Wait for Arduino to initialize

# Load YOLOv4 Model
net = cv2.dnn.readNet("yolov4.weights", "yolov4.cfg")

# Load Object Names
classes = []
with open("coco.names", "r") as f:
    classes = f.read().strip().split("\n")

# Define target classes and known widths (for distance estimation)
TARGET_CLASSES = {"person": 40, "car": 180, "motorcycle": 80, "bus": 250, "truck": 250, "bicycle": 65}
FOCAL_LENGTH = 700  # Estimated focal length, adjust if necessary
DISTANCE_THRESHOLD = 60  # Stop motor if distance < 60 cm

# Open Webcam
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

# Set resolution to 720p
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

# Distance Calculation Function
def calculate_distance(known_width, focal_length, object_width):
    if object_width == 0:
        return 9999
    return (known_width * focal_length) / object_width

# Non-Maximum Suppression (NMS) Parameters
CONF_THRESHOLD = 0.5  # Minimum confidence
NMS_THRESHOLD = 0.4   # Overlap threshold for NMS

while True:
    ret, frame = cap.read()
    if not ret:
        break

    height, width, _ = frame.shape

    # Preprocess frame for YOLOv4
    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), swapRB=True, crop=False)
    net.setInput(blob)
    layer_names = net.getUnconnectedOutLayersNames()
    outputs = net.forward(layer_names)

    boxes, confidences, class_ids = [], [], []

    # Process detections
    for output in outputs:
        for detection in output:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > CONF_THRESHOLD:
                class_name = classes[class_id]
                if class_name in TARGET_CLASSES:
                    center_x, center_y, obj_width, obj_height = (detection[0:4] * np.array([width, height, width, height])).astype(int)
                    x, y = int(center_x - obj_width / 2), int(center_y - obj_height / 2)
                    boxes.append([x, y, obj_width, obj_height])
                    confidences.append(float(confidence))
                    class_ids.append(class_id)

    # Apply Non-Maximum Suppression (NMS)
    indices = cv2.dnn.NMSBoxes(boxes, confidences, CONF_THRESHOLD, NMS_THRESHOLD)

    best_distance = 9999
    best_class_name = "none"

    # Draw final detections after NMS
    if len(indices) > 0:
        for i in indices.flatten():
            x, y, w, h = boxes[i]
            class_name = classes[class_ids[i]]
            distance = calculate_distance(TARGET_CLASSES[class_name], FOCAL_LENGTH, w)

            # Update best distance and class
            if distance < best_distance:
                best_distance = distance
                best_class_name = class_name

            # Draw bounding box and display distance
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(frame, f"{class_name} {int(distance)} cm", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Send best detected object to Arduino
    if best_distance < 9999:
        data_to_send = f"{best_class_name},{int(best_distance)}\n"
        ser.write(data_to_send.encode())
        print(f"Sent to Arduino: {data_to_send.strip()}")

    # Show frame with bounding boxes
    cv2.imshow("AI Speed Control System", frame)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
cap.release()
cv2.destroyAllWindows()
ser.close()
